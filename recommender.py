# -*- coding: utf-8 -*-
"""Recommendation Engine

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_-rOwAqQa4kiuLZqgEgrLkFFYOHQtCa6
"""

import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
import json

def load_data():
    """
    Load and preprocess the Instacart dataset.
    This function loads the necessary CSV files from the Instacart dataset,
    merges them, and prepares a transaction list suitable for market basket analysis.
    """
    try:
        print("Loading data...")
        # Load the datasets
        order_products_prior = pd.read_csv('./instacart-market-basket-analysis/order_products__prior.csv')
        products = pd.read_csv('./instacart-market-basket-analysis/products.csv')
        orders = pd.read_csv('./instacart-market-basket-analysis/orders.csv')
        print("Data loaded successfully.")
    except FileNotFoundError:
        print("Error: Make sure the Kaggle dataset is downloaded and extracted in a folder named 'instacart-market-basket-analysis' in the same directory as the script.")
        return None, None

    print("Preprocessing data...")
    # Merge the datasets to get product names
    order_products_prior = pd.merge(order_products_prior, products, on='product_id', how='left')
    order_products_prior = pd.merge(order_products_prior, orders, on='order_id', how='left')

    # Create a customer-centric view of purchases
    customer_orders = order_products_prior.groupby('user_id')['product_name'].apply(list).reset_index()

    # Create a list of transactions (each transaction is a list of products in an order)
    transactions = order_products_prior.groupby('order_id')['product_name'].apply(list).tolist()
    print("Data preprocessing complete.")

    return transactions, products['product_name'].unique().tolist()

def get_recommendations(transactions, product_list):
    """
    Generate association rules using the Apriori algorithm.
    This function takes a list of transactions, converts it into a one-hot encoded
    format, runs the Apriori algorithm to find frequent itemsets, and then
    generates association rules.
    """
    print("Encoding transactions for Apriori...")
    # One-hot encode the data
    from mlxtend.preprocessing import TransactionEncoder
    te = TransactionEncoder()
    te_ary = te.fit(transactions).transform(transactions)
    df = pd.DataFrame(te_ary, columns=te.columns_)
    print("Transaction encoding complete.")

    print("Running Apriori algorithm...")
    # Run Apriori
    frequent_itemsets = apriori(df, min_support=0.001, use_colnames=True)
    print("Apriori complete. Found {} frequent itemsets.".format(len(frequent_itemsets)))

    print("Generating association rules...")
    # Generate rules
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.1)
    print("Association rule generation complete.")

    # Convert antecedents and consequents to lists for JSON serialization
    rules['antecedents'] = rules['antecedents'].apply(lambda x: list(x))
    rules['consequents'] = rules['consequents'].apply(lambda x: list(x))

    return rules

def main():
    """
    Main function to run the recommendation engine.
    """
    transactions, product_list = load_data()
    if transactions:
        rules = get_recommendations(transactions, product_list)

        # Save the rules and product list to JSON files for the web app
        print("Saving rules and product list to JSON files...")
        rules.to_json('recommendation_rules.json', orient='records')
        with open('product_list.json', 'w') as f:
            json.dump(product_list, f)
        print("Files saved successfully. You can now run the web interface.")

if __name__ == '__main__':
    main()